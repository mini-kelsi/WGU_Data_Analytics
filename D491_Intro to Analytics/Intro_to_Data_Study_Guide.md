## Section 1 - Careers and Goals  

- **Define Data Analytics**
  - *The process of analyzing data to extract insights*
   
- **Define Data Science**
  - *The practice of using statistical methods to extract insights from data*
   
- Differentiate between data analytics and data science
  - **Data science focuses on _developing new algorithms and models_, while data analytics focuses on using _existing models_ to analyze data.**

- Identify data analytics projects
  - **Descriptive Analytics**
    > Focuses on *summarizing and describing* historical data to provide insights to past trends and patterns.
    > "What happened?" "How many times did it happen?"
  - **Diagnostic Analytics**
    > Identify the *root causes* of specific outcomes or events.
    > "Why did an event happen?" "What caused it to happen?"
  - **Predictive Analytics**
    > Forecast future outcomes.
    > "Why did an even happen?" "Why caused it to happen?"
  - **Prescriptive Analytics**
    > Recommends actions that can be taken to optimize or improve a situation.
    > "What should we do?" "How can we prepare for it?"
  - **Exploratory Analytics**
    > Involves exploring and analyzing data to identify potential trends, patterns ,and relationships.
    > Often used when their is *no clear objective or question to answer.*
   
- Identify the fuctions of a specific career
    > [Roles and Career Page](https://github.com/mini-kelsi/WGU_Data_Analytics/blob/WGU/D491_Intro%20to%20Analytics/Roles%20and%20Careers.md)
    
- List roles and fuctions
    > [Roles and Careers Page](https://github.com/mini-kelsi/WGU_Data_Analytics/blob/WGU/D491_Intro%20to%20Analytics/Roles%20and%20Careers.md)
    
- Identify the responsibilities of a data analyst in a data analystics project
- List job skills for each role
    > [Roles and Careers Page](https://github.com/mini-kelsi/WGU_Data_Analytics/blob/WGU/D491_Intro%20to%20Analytics/Roles%20and%20Careers.md)
    
- Identify key stakeholders
   - Project team members and senior management
     
- Iteract with stakeholders
  
- **Define the roles of the stakeholders in the data analytics projects**
  - Project Sponsor
     > Executive who has authorized the project and is responsible for ensuring the project aligns with the company's strategic goals.
   - Project Manager
     > Oversees the project's day-to-day operations, including coordinating with stakeholders and ensuring that the project stays on track.
   - Financial Operations
     > Responsible for managing the budget and finances of the project.
   - Database Administrator
     > Responsible for managing the data infrastructure and ensuring that the data is stored securely and efficiently.
   - Researchers
     > Responsible for interpreting the results of specific data.
   - Partners
     >External stakeholders collaborating with the company on the project.
   - End Users (Customers)
     >Ultimate beneficiaries of the project, as they will benefit from a more effient and optimized inventory management system.

  ## Section 2 - The Data Analytics Lifecycle

- Identify & describe the discovery phase
  > First phase of the Data Analytics Life Cycle.
  
- **Explain the purpose fo the discovery phase**
  > *To understand the business problem and develop initial hypotheses*
  
- Define the question of interest of the data analytics project
  > What is the team attempting to achieve by doing the project, and what will be considered "good enough" as an outcome of the project?
  
- Assess the resources or resource contraints of the data analytics project
  > Ensure the project team has the right mix of domain experts, customers, analytic talent, and project management to be effective. Also evaluate how much time is needed and if the team has the right breadth and depth of skills.
  
- Define outcomes of the data analytics project
  > Gathering enough data to draft an analytics plan and share it for peer review.  Also developing a success criteria to clarify the problem definition and help the team when it comes time to make choices about the analytical methods being used later in the project.
  
- Identify & describe the **data preparation phase**
  > Can work with the data and perform analytics throughout the project.  The team needs to create a robust environment in which it can explore the data that is separate from a production environment.
  
- **Explain the purpose of the data preparation phase**
  > *To clean, normalize, and transform data*
  >  *Understanding the data in detail is critiacal to the success of the project.*
  
- Identify sources of data
  > Corporate Information System, or data warehouse
  
- Identify the **common tools for data preparation**
  - **_OpenRefine_**
    >OpenRefine is a free, open-source tool for working with meesy data, making it suitable for data preparation tasks.

- Identify **steps for the data preparation phase**
  > *Preparing Analytic Sandbox, extract and transform data, condition data, explore visually*
  
- Identify & describe the **model planning phase**
  > *This is the phase where the most suitable models are chosen based on the business goals and the types of relationships that need to be discovered in the data.*
  > *Focuses on identifying candidate models for clustering, classifying or finding relationships and ensuring analytical techniques align with business objectives.*
  
- Explain the purpose of the **modeling planning phase**
  > *The team explores data relationships, selects key variables, and identifies the most suitable modesl for the project.*
  > *Identifying methods and alighing techniques with objectives*
  
- Identify the activities of the data modeling phase
   - Decision Tree
   - Logisitc regression
   - automatic relevance determination
   - multiple linear regression
   - neural network
  
- Identify **common tools for the model planning phase**
  - **_KNIME_**
  
   |Common Tools | Info |
  |---|---|
   |R | has a complete set of modeling capabilities and provides a good environment for building interpretive models with high-quality code.  Also has the ability to interface with databases via an ODBC connection and execute statistical tests and analyses against Big Data via an open source connection. |
   | SQL Analysis Services| can perform in-database analytics of common data mining functions, involved aggregations, and basic predictive models.|
   |SAS/ACCESS | users can connect to relational databases (such as Oracle or Terdata) and data warehouse appliances, files, and enterprise applications (such as SAP and Salesforce.com).|
  
- Identify common models used in the model planning phase
  >
  
- Identify & describe the **model execution phase**
  > *Use datasets to enable the data scientist to develop the analytical model and train it while holding aside some data to test it.*
  
- Explain the purpose of the model execution phase
  > To develope datasets for testing, training and production purposes, builds and executes models based on the planning phase, and evaluates the need for more robust tools or enviroments for executing models and workflows.
  
- Identify the activites of the model execution phase
  
- Identify the **common tools for the model execution phase**
  - **_SAS Enterprise Miner_**
    > A commercial tool specifically designed for model building and execution.
  
- Identify & describe the **communicate results phase**
  >*Phase where the team compares the outcomes of the modeling to the criteria established for success and failure.*
  
- Explain the purpose of the communicate results phase.
  > Presenting findings and outcomes to stakeholders

- Identify the activities of the communicate results phase
  > The team must determine wither the data and model will prove or disprove the hypotheses outlined in Phase 1.  Also, the team has to to determine if the results are statistically significant and valid.  If not, thoughts of adjustments need to be discussed.
  
- Identify the **common tools for communicating results**
  - Data visualization tools and presentation software
  - Dj.3s
    
- Identify & describe the **operationalize phases**
  > *Communicate project benefits, set up the pilot project, and deploy in production*
  
- Explain the purpose of the operationalize phase
  > To pilot the model, refine it, and fully deploy it.
  
- Identify the *key outputs* for each of the *main stakeholders*

  | Stakeholder | Key Outputs |
  |---|---|
  |Project Sponsor | Presentation for Project Sponsor|
  |Project Manager| -|
  | BI Analyst | Presentation for Analysts |
  | DBA | Techical Specs, Code |
  | Data Engineer | Techical Specs, Code |
  | Data Scientist | Presentation for Analyst, Code |
  | Business User | Presentation for Project Sponsors |
  

  ## 1.3 Defining Values for Success

- Identify business questions
  
- Explain how to answer a descriptive analytics question
  
- Explain how to answer a dianostic analytics question
  
- Explain how to answer a predictive analytics question
  > First collect and analyze historical data to identify patterns and trends that may indicate future outcomes. After analyzing the relevant data, ,predictive models can forecast outcomes based on current and historical data.
  
- Explain how to answer a prescriptive analytics question
  
- Identify the methods of collecting from different sources
  
- Identify the sources of data
   - Surveys
   - Interviews
   - Focus Groups
   - Web Scraping
     
- Identify data quality requirements for a specific analytics project
    - If the data is:
         - accurate
         - complete
         - timely
         - relevant
           
- Identify data analytics techniques
- List the impacts of different data analytic techniques
- Identify when to use a particular analysis or reporting technique
- Identify the appropiate visualization fro a particular quesion
- Differentiate between data anlaytics techniques
- Identify the data requirements for different data analytics techniques
- Identify the correct metrics for a given data analytics problem

  | Metric | Data|
  |---|---|
  |Range | Give data about the spread of all possible data|
  |Median | The middle value in a dataset when the data is arranged in numeric order |
  

## Additional Topics to Know

- Key difference between Careers and Roles (Dara Scientiest, Data Engineer, Decision Scientist, and Data Analyst)
- What does each role do within each part of the data anlaytics lifecycle?
- Data analytics techniques
- Regression (logical & linear)
    - Regression analysis is a statistical technique used to determine the relationship between a dependent variable and one or more independent variables.
    - Logical Regression
      > Requires a binary dependent variable to make probailistic assessments throughout any scenario.
    - Linear Regression
      > Help to predict a continuous variable
      
- Clustering
   - A technique that groups similar objects or data points into clusters based on their similarity.  **Continuous data** is necessary for performing cluster analysis because it allows for the calculation of distance or similarity between data points.
       
- K-means
- P - values
    - Measure that assesses the validity of a correlation between two variables during the communicate results phase.
      
- Naive Bayes Analysis
    - Classification model based on the concept of probability and assigns class labels to instances based on the possibility of belonging to a particular class.
      
- Oversampling
- Customer Life Cycles
- Subscribtion models
- Roles of software applications
- Statistical models
- Imputation
    - Common data cleaning task that is used to address missing data in a data set.
      
- Hadoop
    - An open-source framework designed for the distrbuted processing of large datasets **across clusters of computers.**
    - Can handle massive parallel ingestin and custom analysis for web traffic parsing, GPS location analytics, and combining unstructured data feeds from multiple sources.
      
- Data Wrangler
    - Process of converting unstructured data into structured data
      
- DS.js
   - Data visualization tool to create web based visualizations
     
- Type 1 errors
   - Rejection of the null hypothesis when the null hypothesis is true.  The probability of making a type I error is called alpha, and type I errors are known as *false-positive errors.*
     
- Type 2 errors
    - Acceptance of a null hypothesis when the null hypothesis is false.  The probability of making a type II error is callled beta, and type II errors are also known as *false-negative errors.*
      
- Quantitative Data
    - interval, ratio
      
- Qualitative Data
    - nominal, ordinal
      
- Correlation Coefficient
- ARIMA Model
  
