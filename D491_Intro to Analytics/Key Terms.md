## 1.1 What is Data Analytics?  

- **Data Analytics**
  - A coming together to solve a business problem through the creative use of data and statistical modeling to tell a compelling story that drives strategic action and results in business value

- **Data Science**
  - A field of study that involves using computational and statistical techniques to extract insights and knowledge from data.

- Variables
  - A container or storage location that holds a value; variables can be manipulated throughout the data analysis process to achieve the necessary results

  ## 1.2 Roles and Careers

- Key Performance Indicator (KPI)
    - Used to evaluate the performance of an organization, a department, or an individual against its ovjectives and goals,  KPIs measure the progression toward those targets and give insights on continuous improvements; this allows organizations the ability to make an informed decision

- **A/B Testing**
  - A mthod of comparing two versions of an application to determine which one performs better; this allows organizations to visually see which method works best with their enviroments

- Holdout Testing
  - A particular cases of A/B testing in which one (control)group recieves no intervention and the other (test) group revcieves a test application

- Algorithm
  - A set of instructioins or steps that a program follows to solve particular problems or perform specific task

- Variables
  - A container or  storage location that holds a value; variables can be manipulated throughout the data analysis process to achieve the necessary results
 
- Data Lakes
  - A storage place that allows organizations to store large amounts of *stuctured* and *unstructured* data in its true format and allows it to scale until it is needed for applications

## 1.3 Key Stakeholders  

- **Stakeholders**
  - Any person, group, or organization with an iterest or concern in the activities, decisions, or outcome of the organization or business

- Scope
  - Refers to the boundaries of a project, including the objectives, goals, deliverables, task, and resources required to complete the project successfully

- **Project Sponsor**
  - A key stakeholder who provides the project with the necessary support and resources and ensures that the project is aligned with organization's goals and values
 
- **Project Manager**
  - Leads the team from the planning to completion phases of a project, ensuring that it meets the project's goals within the specified time, budget, and resource restraints
 
- **Financial Operation**
  - Manage the project's financial resources; are involved in planning, budgeting, and reporting processes
 
- **Database Administrator**
  - Ensures the project's data is organized, secured, and easily accessible by designing, implementing, and maintaining the project's database system
 
- **Researcher**
  - Design and execute research studies, collect and analyze data, and interpret research findings

- **Partners**
  - Individuals involved in the project's development, objectives, and execution
  - partners can being valuable resources, expertise, and market knowledge to the organizations, and their success is often closely tied to the business's success

## 2.1 The Data Analytics Lifecycle

- Data Analytics Lifecycle
  - A structured approach to address big data issues and data science projects, consisting of six phases that help teams derive actionable insights from data

- **Big Data**
  - Refers to the vast amount of information colleted, sotred, and analyzed by businesses and organizations
  - Its unique aspects can differ between organizations and include up to seven charateristics
  - However, for this course, we will focus on the main four * variety, velocity, veracity, and volume*

- Variety
  - The diverse types of data, including structured (like spreadsheets), semi-structured (such as emails), and unstructured formates (like social media posts)
  - Big data comes from numerous sources, including text, images, videos, social media interactions, and sensor data

- Velocity
  - The speed at which data is produced, collected, and processed
  - In the context of big data, velocity refers to the need for quick analysis and decision-making based on the data gathered

- Veracity
  - The accuracy, reliability, and quality of the data collected and analyzed
  - Ensuring data veractiy is essential for gaining valuable insights and making informed decisions

- Volume
  - The sheer amount of data generated and handled by businesses
  - Big data invovles dealing with enormous quantities of data, rnaging from terabytes to petabytes and beyound, which can be challenging in terms of storage and processing

## 2.2 Discovery Phase

- Resources
  - Items necessary for a successful project
  - Can include items such as technology, tools, systems, data, and people

- **Framing**
  - The process of stating the data analytics problem to be solved

- Hypothesis
  - An initial idea that a data analytics team can test using available data

## 2.3 Data Preparation Phase

- Corporate Data Warehouse
  - A centralized sotrage system for a company's data that is often the ideal location for data mining task

- Data Availability
  - Refers to the accessibility of data from various sources like departmental databases, operational systems, or external sources, which influences the selection process in the data preparation phase

- Data Cleaning
  - Refers to processes for handling errors, missing data, and other problems in dirty data

- Data Complexity
  - Refers to the intricacy and structure of the data, which affects the amount of data required for the analytics process

- Qualitative data types
  - Nominal
  - Ordinal

- Quantitative Data Types
  - Interval
  - Ratio

- **R**
  - A programming language and software framwork for statistical analysis and graphics, available under the GNU General Public License

- Type I Error
  - Rejection of the null hypothesis when the null hypothesis is true.  The probability of making a type I error is called alpha, and type I errors are also known as false-positive errors.

- Type II Error
  - Acceptance of a null hypothesis when the null hypothesis is a false.  The proability of making a type II error is called beta, and type II errors are also known as false-negative  errors.

## 2.4 Model Planning Phase

- **Candidate Models**
  - Potential models for clustering, classifying, or finding relationships in data

- Dataset Structure
  - Refers to the arragnement and organization of data used in the analysis process

- Analytical Techniques
  - Methods and tools used to anlayze and process data to achieve business objectives
 
- Variable Selection
  - The process of identifying essential predictors and variables to include in the model

- Sturctured Data
  - Data organized in a specific format or schema, making it easier to analyze

- Unstructured Data
  - Data that lacks a specific format or structure, often requiring additional processing before analysis

## 2.5 Model Building Phase

- *Training Data*
  - The dataset used for model development, where the model learns pattterns and relationships in the data

- *Test Data*
  - A separate dataset, also called hold-out data, used to evaluate the model's performance and accuracy on unseen data

- **Model building phase**
  - Includes developing and fitting an analytical model on the training data

- Model Assessment
  - The process of evaluating the technical merits of a model, such as accuracy, comprehensibility, and confidence in predictions

- *Error Rate*
  - The percentage of records classified correctly or incorrectly, used to measure the accuracy of a model

- Lift
  - A measure that indicates the change in concentration of a particular class when the model is used to select a group from the genral population

- ROC Charts
  - A performance measurement for binary response models, comparing the true positive rate with the false positive rate

## 2.6 Communicate Results Phase

- Success and Faulure Criteria
  - Benchmarks used to determine whether the analysis has met its objectives

- Stakeholders
  - Individuals or groups interested in the project and its outcomes

- Speculative Analysis
  - An analyst's commentary and hypotheses that go beyond the statistically demonstrated evidence

- Statistical Significance
  - Meaasures whether the observed results are likely to have occurred by chance or if they indicate genuine relationship between variables

- Model Refinement
  - The process of adjustin and improving the analytical model based on the findings and feedback from stakeholders

- Control Group
  - A group in an experiment that does not receive treatment or intervention, serving as a baseline for comparison

## 2.7 Operationalize Phase

- Key Performance Metrics
  - Business-relevant measures that will be communicated on a dashboard for ongoing monitoring and decision support

- Pilot Project
  - A small-scall deployment of the model in a live setting, allowing the data science team to manage risk, evaluate performance, and make adjustments before a full-scale deployment

- Production Environment
  - The system where the model is deployed and integrated with existing business processes as opposed to a sandbox or testing environment

- Model Accuracy Monitoring
  - The ongoing process of checking the model's performance and retaining it if its accuracy degrades over time

- Out-of-Bounds Operation
  - A situation in whihc the inputs to the model are outside the range it was trained on, potentially causing inaccurate or invalid outputs

## 3.1 Asking the Right Questions

- Engagement
  - The level of interaction between users and a particular platform or piece of content
  - Can include website traffic
  - Social media likes, shares, and comments
  - Email opens
  - Click-through rates
  - And any other measureable action that indicates user interest and involvement

- Algorithm
  - A step by step instructions for solving a problem or compleing a task
  - In data analytics, algorithms process and analyze large amounts of data to extract valuabe insights and patterns for making informed business decisions, including clustersing algorithms, decision tree algorithms, and more

## 3.2 Unlocking the Data Within

- Customer Segmentation
  - Divides customers into different groups based on similar characteristics such as demographics, behavior, and preferences
  - This allows businesses to tailor their marketing strategies and offerings to different customer groups, leading to more effective and efficient use of resources

- Directed Data Mining
  - Used when the historical data contains examples of what is being looked for, a *target variable*
 
- Exploratory Data Mining
  - Produces insights or answers questions, rather than producing models used for scoring

- Market Research
  - Collects and analyzes information about a market, including its size, trends, competitors, and customer preferences, and helps businesses make informed decisions about their products and services, pricing, promotion, and distribution strategies

- Undirected Data Mining
  - Does not use a target variable

## 3.3 Organizational Impact

- Machine Learning
  - A branch of artifical intelligence focused on developing algorithms and models that allow computers to learn and make predictions or decisions based on data
  - In the context of a data analytics course, machine learning is a set of techniques and tool used to analyze and derive insights from large and complex datasets

- Optimization
  - The process of finding the best solution to a problem or maximizing or minimizing an objective function, subject to constraints

- Conversion Rate
  - A metric that measures the percentage of website visitors who complete a desired action, such as purchasing or filling out a form

- Click-Through Rate (CTR)
  - A metric that measures the percentage of people of people who click on a link or advertisement

- Customer Lifetime Value (CLV)
  - A metric that measures the total value of a customer to a business throughout their relationship

- Churn Rate
  - A metric that measures the percentage of customers who stop doing business with a company over a certain period

- Customer Acquisition Cost (CAC)
  - A metric that measures the cost of acquiring a new customer
 
- Return on Investment (ROI)
  - A metric that measures an investment's profitability

- Bounce Rate
  - A metric that measures the percentage of website visitors who leave after viewing only one page

- Time on Site
  - A metric that measures a user's time on a website

- Engagement Rate
  - A metric that measures the level of engagement with content or advertisements, surch as likes, comments, and shares on social media

- Revenue Growth
  - A metric that measures the increase in revenue over a specific period

- **Predicitve Analytics**
  - Uses statistical algorithms and machine learning techniques to analyze historical data and predict future events or outcomes
  - For example, a healthcare provider might use predictive analytics to identify patients who are at high risk for certain diseases based on their medical history and lifestyle factors

- **Clustering**
  - A technique used to group similar data points based on their characteristics or attributes
  - For example, a marketing team might use clustering techniques to group customers with similar purchasing behaviors to create targeted marketing campaigns

- **Regression**
  - A statistical method for examining the relationship between a dependent variable and one or more independent variables
  - For example, a business might use regression analysis to determine how much changes in advertising spending affect sales

- **Data Visualization**
  - Uses graphical representations to communicate complex data and insights to stakeholders
  - For example, a business might use data visualization techniques to create interactive dashboards that display key performance indicators and allow executives to monitor the businesss's health in real time

- Neural Networks
  - A class of machine learning algorithms used in data anlaytics that are inspired by the structure and function of the human brain
  - They are a type of artificial neural network that can learn and make predicitons on complex data patterns
 
